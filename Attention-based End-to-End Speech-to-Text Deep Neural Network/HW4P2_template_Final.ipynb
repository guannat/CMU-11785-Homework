{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4P2_template_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTGPr98x0yjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81c6c0a0-f6fb-42a0-e7c4-64927491e9ce"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "import torch.optim as optim\n",
        "import torch.nn.utils as utils\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import random\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.nn.utils.rnn import *\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "print(cuda, sys.version)\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "np.random.seed(5111785)\n",
        "torch.manual_seed(5111785)\n",
        "\n",
        "LETTER_LIST = ['<sos>', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', \\\n",
        "         'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '-', \"'\", '.', '_', '+', ' ', '<eos>']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True 3.7.10 (default, Feb 20 2021, 21:17:23) \n",
            "[GCC 7.5.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KysVajKRirFj"
      },
      "source": [
        "Dictionaries. Index2Letter, Letter2Index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ZFmcvE1pkDNi"
      },
      "source": [
        "def create_dictionaries(letter_list):\n",
        "    '''\n",
        "    Create dictionaries for letter2index and index2letter transformations\n",
        "    '''\n",
        "    letter2index = dict(zip(letter_list, range(len(letter_list))))\n",
        "    index2letter = dict(zip(range(len(letter_list)),letter_list))\n",
        "    return letter2index, index2letter\n",
        "\n",
        "def transform_letter_to_index(raw_transcripts):\n",
        "    '''\n",
        "    Transforms text input to numerical input by converting each letter \n",
        "    to its corresponding index from letter_list\n",
        "\n",
        "    Args:\n",
        "        raw_transcripts: Raw text transcripts with the shape of (N, )\n",
        "    \n",
        "    Return:\n",
        "        transcripts: Converted index-format transcripts. This would be a list with a length of N\n",
        "    '''  \n",
        "\n",
        "    transcripts = []\n",
        "    for i in range(raw_transcripts.shape[0]):\n",
        "      trans_index = [letter2index[j]  for j in ' '.join([q.decode(\"utf-8\") for q in raw_transcripts[i]])]\n",
        "      # trans_index = [letter2index['<sos>']] + trans_index + [letter2index['<eos>']]\n",
        "      trans_index = trans_index + [letter2index['<eos>']]\n",
        "      transcripts.append(torch.Tensor(trans_index))\n",
        "    \n",
        "    return transcripts\n",
        "\n",
        "\n",
        "def transform_letter_to_index_simple(raw_transcripts):\n",
        "    '''\n",
        "    Transforms text input to numerical input by converting each letter \n",
        "    to its corresponding index from letter_list\n",
        "\n",
        "    Args:\n",
        "        raw_transcripts: Raw text transcripts with the shape of (N, )\n",
        "    \n",
        "    Return:\n",
        "        transcripts: Converted index-format transcripts. This would be a list with a length of N\n",
        "    '''  \n",
        "\n",
        "    transcripts = []\n",
        "    for i in range(raw_transcripts.shape[0]):\n",
        "\n",
        "      trans_index = [letter2index[j]  for j in ' '.join([q for q in raw_transcripts[i]])]\n",
        "      trans_index = trans_index + [letter2index['<eos>']]\n",
        "      transcripts.append(torch.Tensor(trans_index))\n",
        "    \n",
        "    return transcripts\n",
        "\n",
        "       \n",
        "# Create the letter2index and index2letter dictionary\n",
        "letter2index, index2letter = create_dictionaries(LETTER_LIST)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhSD0FOXm5Q6"
      },
      "source": [
        "class MyDataset(data.Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # For testing set, return only x\n",
        "        if self.Y == None:\n",
        "            return torch.tensor(self.X[index].astype(np.float32))\n",
        "        # For training and validation set, return x and y\n",
        "        else:\n",
        "            return torch.tensor(self.X[index].astype(np.float32)), torch.tensor(self.Y[index])\n",
        "\n",
        "\n",
        "def collate_train_val(data):\n",
        "    \"\"\"\n",
        "    Return:\n",
        "        pad_x: the padded x (training/validation speech data) \n",
        "        pad_y: the padded y (text labels - transcripts)\n",
        "        x_len: the length of x\n",
        "        y_len: the length of y\n",
        "    \"\"\"\n",
        "\n",
        "    x_len = torch.LongTensor([len(seq[0]) for seq in data])\n",
        "    y_len = torch.LongTensor([len(seq[1]) for seq in data])\n",
        "\n",
        "    X = [i[0] for i in data]\n",
        "    Y = [i[1] for i in data]\n",
        "    pad_x = pad_sequence(X,batch_first=True)\n",
        "    pad_y = pad_sequence(Y,batch_first=True, padding_value = letter2index['<eos>']) \n",
        "\n",
        "    return pad_x,pad_y,x_len,y_len\n",
        "\n",
        "def collate_test(data): \n",
        "    \"\"\"\n",
        "    Return:\n",
        "        pad_x: the padded x (testing speech data) \n",
        "        x_len: the length of x\n",
        "    \"\"\"\n",
        "    x_len = torch.LongTensor([len(seq) for seq in data])\n",
        "\n",
        "    X = [i for i in data]\n",
        "    pad_x = pad_sequence(X,batch_first=True)\n",
        "\n",
        "    return pad_x,x_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIlWSn3AoC7q"
      },
      "source": [
        "def transform_index_to_letter(index,startindex, stopindex):\n",
        "    index_to_letter_list = []\n",
        "    for tr in index:\n",
        "      curr = \"\"\n",
        "      for i in tr:\n",
        "        if i in stopindex:\n",
        "          break\n",
        "        elif i in startindex:\n",
        "          pass\n",
        "        else:\n",
        "          curr += index2letter[i]\n",
        "      index_to_letter_list.append(curr)\n",
        "    return index_to_letter_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTKMqJwui4BR"
      },
      "source": [
        "# Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJukRb802lQI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87959ba3-93fb-45f8-e0c3-51a6413187e5"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/competitions/HW4P2\n",
        "# Load the training, validation and testing data\n",
        "train_data = np.load('train.npy', allow_pickle=True, encoding='bytes')\n",
        "valid_data = np.load('dev.npy', allow_pickle=True, encoding='bytes')\n",
        "test_data = np.load('test.npy', allow_pickle=True, encoding='bytes')\n",
        "\n",
        "# Load the training, validation raw text transcripts\n",
        "raw_train_transcript = np.load('train_transcripts.npy', allow_pickle=True,encoding='bytes')\n",
        "raw_valid_transcript = np.load('dev_transcripts.npy', allow_pickle=True,encoding='bytes')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/competitions/HW4P2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "OJKdna5VnIJM"
      },
      "source": [
        "# TODO: Convert the raw text transcripts into indexes\n",
        "train_transcript = transform_letter_to_index(raw_train_transcript)\n",
        "valid_transcript = transform_letter_to_index(raw_valid_transcript)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = MyDataset(train_data,train_transcript)\n",
        "valid_dataset = MyDataset(valid_data,valid_transcript)\n",
        "test_dataset = MyDataset(test_data,None)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=64, collate_fn = collate_train_val,num_workers=0, pin_memory=True)\n",
        "valid_loader = DataLoader(valid_dataset, shuffle=False, batch_size=128, collate_fn = collate_train_val,num_workers=0, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=128, collate_fn = collate_test,num_workers=0, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjSHgtjJj5RB"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zgqnLF5KbPY"
      },
      "source": [
        "# Lockdropout\n",
        "# Code from TA and https://pytorchnlp.readthedocs.io/en/latest/_modules/torchnlp/nn/lock_dropout.html \n",
        "from torch.autograd import Variable\n",
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "\n",
        "class LockedDropout(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, x, dropout=0.5):\n",
        "    # x': (B, L, C)\n",
        "    if dropout == 0 or not self.training:\n",
        "      return x\n",
        "    mask = x.data.new(x.size(0), 1, x.size(2))\n",
        "    mask = mask.bernoulli_(1 - dropout)\n",
        "    mask = Variable(mask, requires_grad=False) / (1 - dropout)\n",
        "    mask = mask.expand_as(x)\n",
        "    return mask * x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVZKZjhm41UD"
      },
      "source": [
        "Pyramidal Bi-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfpIMUDzCvT3"
      },
      "source": [
        "class pBLSTM(nn.Module):\n",
        "    '''\n",
        "    Pyramidal BiLSTM\n",
        "    Read paper and understand the concepts and then write your implementation here.\n",
        "    '''\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(pBLSTM, self).__init__()\n",
        "        self.blstm = nn.LSTM(input_size=input_dim*2, hidden_size=hidden_dim, num_layers=1, bidirectional=True, batch_first=True)\n",
        "        self.dropout = LockedDropout()\n",
        "    def forward(self, x):\n",
        "        x_padded, x_lens = pad_packed_sequence(x, batch_first=True)\n",
        "        x_padded = x_padded[:, :(x_padded.size(1) // 2) * 2, :]  # chop off \n",
        "        x_padded = x_padded.reshape(x_padded.size(0), x_padded.size(1) // 2, x_padded.size(2) * 2)\n",
        "        x_padded = self.dropout(x_padded) # lock dropout layer\n",
        "        x_packed = pack_padded_sequence(x_padded, lengths=x_lens // 2, batch_first=True, enforce_sorted=False)\n",
        "        out, _ = self.blstm(x_packed)\n",
        "        return out "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F9zAQR95P55"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    '''\n",
        "    Encoder takes the utterances as inputs and returns the key, value and unpacked_x_len.\n",
        "    Key and value are linear projections of the output from pBLSTM network for the laster.\n",
        "    '''\n",
        "    def __init__(self, input_dim, encoder_hidden_dim, key_value_size=128):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.cnn_layer = torch.nn.Sequential(\n",
        "            torch.nn.Conv1d(input_dim, encoder_hidden_dim, kernel_size=3, stride=1, padding=1,bias=False),\n",
        "            torch.nn.BatchNorm1d(encoder_hidden_dim),\n",
        "        )\n",
        "\n",
        "        # The first LSTM at the very bottom\n",
        "        self.lstm = nn.LSTM(input_size=encoder_hidden_dim, hidden_size=encoder_hidden_dim, num_layers=1, bidirectional=True, batch_first=True)\n",
        "\n",
        "        # TODO: Define the blocks of pBLSTMs\n",
        "        self.pBLSTM1=pBLSTM(2*encoder_hidden_dim, encoder_hidden_dim)\n",
        "        self.pBLSTM2=pBLSTM(2*encoder_hidden_dim, encoder_hidden_dim)\n",
        "        self.pBLSTM3=pBLSTM(2*encoder_hidden_dim, encoder_hidden_dim)\n",
        "\n",
        "        # The linear transformation for producing Key and Value for attention\n",
        "        # Since you are using bidirectional LSTM, be careful about the size of hidden dimension\n",
        "        self.key_network = nn.Linear(encoder_hidden_dim*2, key_value_size)\n",
        "        self.value_network = nn.Linear(encoder_hidden_dim*2, key_value_size)\n",
        "\n",
        "    def forward(self, x, x_len):\n",
        "        x = x.transpose(1,2)\n",
        "        x = self.cnn_layer(x)\n",
        "        x = x.transpose(1,2)\n",
        "\n",
        "\n",
        "        # Pass through the first LSTM at the very bottom        \n",
        "        packed_sequence = rnn_utils.pack_padded_sequence(x, x_len.cpu(), enforce_sorted=False, batch_first=True) \n",
        "        outputs, _ = self.lstm(packed_sequence)\n",
        "        \n",
        "        # TODO: Pass through the pBLSTM blocks        \n",
        "        outputs=self.pBLSTM1(outputs)\n",
        "        outputs=self.pBLSTM2(outputs)\n",
        "        outputs=self.pBLSTM3(outputs)\n",
        "\n",
        "        # Unpack the sequence and get the Key and Value for attention\n",
        "        linear_input, unpacked_x_len = utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
        "        \n",
        "        keys = self.key_network(linear_input)\n",
        "        value = self.value_network(linear_input)\n",
        "\n",
        "        return keys, value, unpacked_x_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqu-MUM8TjUO"
      },
      "source": [
        "# Reference: recitation code\n",
        "\n",
        "def plot_attention(attention):\n",
        "    plt.clf()\n",
        "    sns.heatmap(attention, cmap='GnBu')\n",
        "    plt.show()\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    '''\n",
        "    Attention is calculated using key, value and query from Encoder and decoder.\n",
        "    Below are the set of operations you need to perform for computing attention:\n",
        "        energy = bmm(key, query)\n",
        "        attention = softmax(energy)\n",
        "        context = bmm(attention, value)\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "    def forward(self, query, key, value, mask):\n",
        "\n",
        "        key = key.to(device)\n",
        "        attention = torch.bmm(key, query.unsqueeze(2)).squeeze(2).to(device)\n",
        "\n",
        "        # mask = torch.arange(context.size(1)).unsqueeze(0) >= lengths.unsqueeze(1)\n",
        "        mask = mask.to(device)\n",
        "\n",
        "        attention.masked_fill_(mask, -1e9)\n",
        " \n",
        "        attention = nn.functional.softmax(attention, dim=1)\n",
        "\n",
        "        out = torch.bmm(attention.unsqueeze(1), value).squeeze(1)\n",
        "        \n",
        "        # attention vectors are returned for visualization\n",
        "        return out, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcTC4cK95TYT"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    '''\n",
        "    As mentioned in a previous recitation, each forward call of decoder deals with just one time step.\n",
        "    Thus we use LSTMCell instead of LSTM here.\n",
        "    The output from the seond LSTMCell can be used as query for calculating attention.\n",
        "    In place of value that we get from the attention, this can be replace by context we get from the attention.\n",
        "    Methods like Gumble noise and teacher forcing can also be incorporated for improving the performance.\n",
        "    '''\n",
        "    def __init__(self, vocab_size, decoder_hidden_dim, embed_dim, key_value_size=128):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=letter2index['<eos>'])\n",
        "        self.lstm1 = nn.LSTMCell(input_size=embed_dim + key_value_size, hidden_size=decoder_hidden_dim)\n",
        "        self.lstm2 = nn.LSTMCell(input_size=decoder_hidden_dim, hidden_size=key_value_size)\n",
        "\n",
        "        self.linear = nn.Linear(key_value_size*2, decoder_hidden_dim)\n",
        "\n",
        "        self.attention = Attention()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.fc1 = nn.Linear(2 * key_value_size, 4 * key_value_size)\n",
        "        self.tanh1 = nn.Tanh()\n",
        "        self.fc2 = nn.Linear(4 * key_value_size, embed_dim)\n",
        "        self.tanh2 = nn.Tanh()\n",
        "\n",
        "        self.character_prob = nn.Linear(2 * key_value_size, vocab_size)\n",
        "        self.key_value_size = key_value_size\n",
        "        self.hidden_dim = decoder_hidden_dim\n",
        "\n",
        "        # weight tying\n",
        "        self.character_prob.weight = self.embedding.weight\n",
        "\n",
        "\n",
        "    def forward(self, key, value, encoder_len, y=None, mode='train',batch_idx=30,Teacher_forcing_rate=0.1):\n",
        "        '''\n",
        "        Args:\n",
        "            key :(B, T, key_value_size) - Output of the Encoder Key projection layer\n",
        "            value: (B, T, key_value_size) - Output of the Encoder Value projection layer\n",
        "            y: (T, text_len) - Batch input of text with text_length\n",
        "            mode: Train or eval mode\n",
        "        Return:\n",
        "            predictions: the character perdiction probability\n",
        "        '''\n",
        "\n",
        "        B, key_seq_max_len, key_value_size = key.shape\n",
        "\n",
        "        if mode == 'train':\n",
        "            max_len =  y.shape[1] # \n",
        "            char_embeddings = self.embedding(y.long()) # ground truth \n",
        "        else:\n",
        "            max_len = 600\n",
        "\n",
        "        # TODO: Create the attention mask here (outside the for loop rather than inside) to aviod repetition\n",
        "        mask = torch.arange(key_seq_max_len).unsqueeze(0) >= encoder_len.unsqueeze(1) # (1, T) >= (B, 1) -> (N, T_max) \n",
        "\n",
        "        predictions = []\n",
        "        prediction = torch.zeros(B, 1).to(device)\n",
        "        hidden_states = [None, None]\n",
        "\n",
        "        # TODO: Initialize the context. Be careful here\n",
        "        context = value[:,0,:].squeeze(1)\n",
        "        attentionPlot = [] # list to generate attenntion plot\n",
        "        char_embed = 0 # initalize with <SOS> \n",
        "\n",
        "        for i in range(max_len):\n",
        "            if mode == 'train':\n",
        "                # TODO: Implement (1) Teacher Forcing and (2) Gumble Noise techniques here\n",
        "                if np.random.random_sample() < Teacher_forcing_rate and i > 0:\n",
        "                    char_embed = char_embeddings[:,i-1]\n",
        "                else:\n",
        "                    char_embed = self.embedding(prediction.argmax(dim=-1))\n",
        "            else:\n",
        "                char_embed = self.embedding(prediction.argmax(dim=-1))\n",
        "\n",
        "            y_context = torch.cat([char_embed, context], dim=1)\n",
        "            hidden_states[0] = self.lstm1(y_context, hidden_states[0])\n",
        "\n",
        "            lstm1_hidden = hidden_states[0][0]\n",
        "            hidden_states[1] = self.lstm2(lstm1_hidden, hidden_states[1])\n",
        "            output = hidden_states[1][0]\n",
        "\n",
        "            # TODO: Compute attention from the output of the second LSTM Cell\n",
        "            context, attention=self.attention(output, key, value, mask)\n",
        "            if batch_idx % 64 == 22:\n",
        "              attentionPlot.append(attention[5].detach().cpu())\n",
        "\n",
        "            output_context = torch.cat([output, context], dim=1)\n",
        "            output_context = self.fc1(output_context)\n",
        "            output_context = self.tanh1(output_context)\n",
        "            output_context = self.fc2(output_context)\n",
        "            output_context = self.tanh2(output_context)\n",
        "            prediction = self.character_prob(output_context)\n",
        "            predictions.append(prediction.unsqueeze(1))\n",
        "\n",
        "        if batch_idx % 64 == 22:\n",
        "          attentions_plot = torch.stack(attentionPlot, dim=1)\n",
        "          plot_attention(attentions_plot)\n",
        "\n",
        "        return torch.cat(predictions, dim=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d35FEZhz5Uhx"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    '''\n",
        "    We train an end-to-end sequence to sequence model comprising of Encoder and Decoder.\n",
        "    This is simply a wrapper \"model\" for your encoder and decoder.\n",
        "    '''\n",
        "    def __init__(self, input_dim, vocab_size, encoder_hidden_dim, decoder_hidden_dim, embed_dim, key_value_size=128):\n",
        "        super(Seq2Seq,self).__init__()\n",
        "        self.encoder = Encoder(input_dim, encoder_hidden_dim, key_value_size=key_value_size)\n",
        "        self.decoder = Decoder(vocab_size, decoder_hidden_dim, embed_dim, key_value_size=key_value_size)\n",
        "\n",
        "    def forward(self, x, x_len, y=None, mode='train',batch_num=0,Teacher_forcing_rate=0.5):\n",
        "        key, value, encoder_len = self.encoder(x, x_len)\n",
        "        predictions = self.decoder(key, value, encoder_len, y=y, mode=mode,batch_idx=batch_num, Teacher_forcing_rate=Teacher_forcing_rate)\n",
        "        return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "jzpCjd9R5VYV"
      },
      "source": [
        "def train(model, train_loader, criterion, optimizer, mode,Teacher_forcing_rate):\n",
        "    model.train()\n",
        "    model.to(device)\n",
        "    runningLoss = 0\n",
        "    perplexity = 0\n",
        "    \n",
        "    # 0) Iterate through your data loader\n",
        "    for batch_idx, (x,y,x_len,y_len) in tqdm(enumerate(train_loader),position=0, leave=True):\n",
        "        optimizer.zero_grad()\n",
        "        # 1) Set the inputs to the device.\n",
        "        x,y,x_len,y_len = x.to(device),y.long().to(device),x_len.to(device),y_len.to(device)\n",
        "\n",
        "        # 2) Pass your inputs, and length of speech into the model.\n",
        "        predictions = model(x, x_len, y=y, mode='train',batch_num=batch_idx,Teacher_forcing_rate=Teacher_forcing_rate)\n",
        "\n",
        "        # 3) Generate a mask based on the lengths of the text\n",
        "        #    Ensure the mask is on the device and is the correct shape.   \n",
        "        mask = torch.zeros(y.size()).T\n",
        "        mask = mask.to(device) # binary\n",
        "        for idx, length_Y in enumerate(y_len):\n",
        "              mask[:length_Y,idx] = 1\n",
        "\n",
        "        # 4. Calculate the loss and mask it to remove the padding part\n",
        "        loss = criterion(predictions.view(-1, predictions.size(2)), y.view(-1)) \n",
        "        masked_loss = torch.sum(loss * mask.view(-1)) / torch.sum(mask)\n",
        "        curr_Loss = masked_loss.item()\n",
        "        curr_Perplex = torch.exp(masked_loss).item() # exponential of the loss-per-word\n",
        "        runningLoss += curr_Loss\n",
        "        perplexity += curr_Perplex\n",
        "\n",
        "        # 5. Backward on the masked loss\n",
        "        masked_loss.backward()\n",
        "        # 6. Optional: Use torch.nn.utils.clip_grad_norm(model.parameters(), 2) to clip the gradie\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 2)\n",
        "        # 7. Take a step with your optimizer\n",
        "        optimizer.step() \n",
        "        # 8. print the statistic (loss, edit distance and etc.) for analysis\n",
        "    print('Training:')\n",
        "    print('Avg-Loss: {:.5f}\\tAvg-perplexity: {:.5f}'.format(runningLoss / len(train_loader), perplexity / len(train_loader)))\n",
        "    del x,y,x_len,y_len\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "def val(model, valid_loader):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    runningDist = 0\n",
        "    tot_sec = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (x,y,x_len,y_len) in tqdm(enumerate(valid_loader),position=0, leave=True):\n",
        "            x,y,x_len,y_len = x.to(device),y.long().to(device),x_len.to(device),y_len.to(device)\n",
        "            predictions = model(x, x_len, y=y, mode='eval')\n",
        "            predText = transform_index_to_letter(predictions.argmax(-1).detach().cpu().numpy(),startindex = [letter2index['<sos>']],stopindex = [letter2index['<eos>']] )    \n",
        "            targetText =transform_index_to_letter(y.detach().cpu().numpy(),startindex = [letter2index['<sos>']],stopindex = [letter2index['<eos>']] )    \n",
        "            for pred, target in zip(predText, targetText):\n",
        "                dist = Levenshtein.distance(pred, target)\n",
        "                runningDist += dist\n",
        "                tot_sec += 1\n",
        "\n",
        "    print('eval:')\n",
        "    print('Avg-distance: {:.5f}'.format(runningDist / tot_sec))\n",
        "    del x,y,x_len,y_len\n",
        "    torch.cuda.empty_cache()\n",
        "    return runningDist / tot_sec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDSHYLPi1cpr"
      },
      "source": [
        "model = Seq2Seq(input_dim=40, vocab_size=len(LETTER_LIST), encoder_hidden_dim=256, decoder_hidden_dim=512, embed_dim=256, key_value_size=128)\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb9D65YZ4lMt"
      },
      "source": [
        "# Training (LAS with teacher forcing )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkIy1Zs0UXwQ",
        "outputId": "d538ef4c-13e0-4a35-a019-bf5c9d4f71a1"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (cnn_layer): Sequential(\n",
              "      (0): Conv1d(40, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
              "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (lstm): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
              "    (pBLSTM1): pBLSTM(\n",
              "      (blstm): LSTM(1024, 256, batch_first=True, bidirectional=True)\n",
              "      (dropout): LockedDropout()\n",
              "    )\n",
              "    (pBLSTM2): pBLSTM(\n",
              "      (blstm): LSTM(1024, 256, batch_first=True, bidirectional=True)\n",
              "      (dropout): LockedDropout()\n",
              "    )\n",
              "    (pBLSTM3): pBLSTM(\n",
              "      (blstm): LSTM(1024, 256, batch_first=True, bidirectional=True)\n",
              "      (dropout): LockedDropout()\n",
              "    )\n",
              "    (key_network): Linear(in_features=512, out_features=128, bias=True)\n",
              "    (value_network): Linear(in_features=512, out_features=128, bias=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(34, 256, padding_idx=33)\n",
              "    (lstm1): LSTMCell(384, 512)\n",
              "    (lstm2): LSTMCell(512, 128)\n",
              "    (linear): Linear(in_features=256, out_features=512, bias=True)\n",
              "    (attention): Attention()\n",
              "    (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
              "    (tanh1): Tanh()\n",
              "    (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
              "    (tanh2): Tanh()\n",
              "    (character_prob): Linear(in_features=256, out_features=34, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQFJX8xuQvc6"
      },
      "source": [
        "# every 15 epoch, teacher forcing rate -=0.1\n",
        "# disable scheduler for first 20 epochs\n",
        "n_epochs = 150\n",
        "Teacher_forcing_rate = 0.9\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss(reduction='none').to(device)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.75, patience=5)\n",
        "mode = 'train'\n",
        "\n",
        "\n",
        "# best_dist = 10000\n",
        "print('best dist',best_dist)\n",
        "for epoch in range(n_epochs):\n",
        "    print('epoch: ',epoch+1, 'learning rate:',optimizer.param_groups[0]['lr'],'teacher forcing rate', Teacher_forcing_rate )\n",
        "    train(model, train_loader, criterion, optimizer, mode,Teacher_forcing_rate)\n",
        "    val_dist = val(model, valid_loader)\n",
        "    if epoch > 19:\n",
        "      scheduler.step(val_dist)\n",
        "    if (epoch % 15 == 14):\n",
        "        Teacher_forcing_rate -= 0.1\n",
        "        Teacher_forcing_rate = max(0.1, Teacher_forcing_rate)\n",
        "    if best_dist > val_dist:\n",
        "      best_dist = val_dist\n",
        "      print('val Dist',best_dist)\n",
        "      torch.save(model, 'model_24.pt') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhEXAZJ94fY5"
      },
      "source": [
        "# Testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Enx2bvQuhaB4",
        "outputId": "eb7431dc-1694-4d34-a958-79c526898be6"
      },
      "source": [
        "def testing(model, test_loader):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    predText_col = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (x,x_len) in tqdm(enumerate(test_loader),position=0, leave=True):\n",
        "            x,x_len = x.to(device),x_len.to(device)\n",
        "            predictions = model(x, x_len, mode='eval')\n",
        "            predText = transform_index_to_letter(predictions.argmax(-1).detach().cpu().numpy(),startindex = [letter2index['<sos>']],stopindex = [letter2index['<eos>']] )    \n",
        "            predText_col.extend(predText)\n",
        "    del x,x_len\n",
        "    torch.cuda.empty_cache()\n",
        "    return predText_col\n",
        "\n",
        "model = torch.load( 'model_24.pt') \n",
        "test_text = testing(model, test_loader)\n",
        "\n",
        "# write csv file\n",
        "with open(\"trial.csv\", 'w') as fh:\n",
        "  fh.write('id,label\\n') \n",
        "  for i in range(len(test_text)):\n",
        "    fh.write(str(i)+ ',' + test_text[i] + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21it [00:16,  1.26it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}